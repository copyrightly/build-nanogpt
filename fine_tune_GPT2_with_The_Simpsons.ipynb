{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb2_GZkJ6ZsC",
        "outputId": "1fc3c6de-42ec-4270-818b-ee95a6a6a214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WtiV_2JcVqI3"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "YRubh8djVusm",
        "outputId": "84665752-0883-491c-c8cc-11e40f2029b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-046e156d-31f2-4564-b47f-5035156e2551\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-046e156d-31f2-4564-b47f-5035156e2551\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving simpsons_script_lines.csv to simpsons_script_lines.csv\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n3vLk7rQXiWH"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2iMdUm1hV6sy"
      },
      "outputs": [],
      "source": [
        "with open('simpsons_script_lines.csv', 'r') as f:\n",
        "    text = f.read()\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "# tokens = enc.encode(text)\n",
        "# tokens = torch.tensor(tokens)\n",
        "# print(f\"loaded {len(tokens)} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rdM32Jf1WIc9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dabcuIaDWEl7",
        "outputId": "b33c8e8d-b76c-4f26-cb9f-8b419f9dfaef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-7fb9962208ac>:1: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('simpsons_script_lines.csv')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id  episode_id  number  \\\n",
              "0  9549          32     209   \n",
              "1  9550          32     210   \n",
              "2  9551          32     211   \n",
              "3  9552          32     212   \n",
              "4  9553          32     213   \n",
              "\n",
              "                                            raw_text timestamp_in_ms  \\\n",
              "0  Miss Hoover: No, actually, it was a little of ...          848000   \n",
              "1  Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n",
              "2  Miss Hoover: I don't know. Although I'd sure l...          856000   \n",
              "3           Lisa Simpson: That life is worth living.          864000   \n",
              "4  Edna Krabappel-Flanders: The polls will be ope...          864000   \n",
              "\n",
              "  speaking_line character_id  location_id       raw_character_text  \\\n",
              "0          True        464.0          3.0              Miss Hoover   \n",
              "1          True          9.0          3.0             Lisa Simpson   \n",
              "2          True        464.0          3.0              Miss Hoover   \n",
              "3          True          9.0          3.0             Lisa Simpson   \n",
              "4          True         40.0          3.0  Edna Krabappel-Flanders   \n",
              "\n",
              "               raw_location_text  \\\n",
              "0  Springfield Elementary School   \n",
              "1  Springfield Elementary School   \n",
              "2  Springfield Elementary School   \n",
              "3  Springfield Elementary School   \n",
              "4  Springfield Elementary School   \n",
              "\n",
              "                                        spoken_words  \\\n",
              "0  No, actually, it was a little of both. Sometim...   \n",
              "1                             Where's Mr. Bergstrom?   \n",
              "2  I don't know. Although I'd sure like to talk t...   \n",
              "3                         That life is worth living.   \n",
              "4  The polls will be open from now until the end ...   \n",
              "\n",
              "                                     normalized_text word_count  \n",
              "0  no actually it was a little of both sometimes ...         31  \n",
              "1                                wheres mr bergstrom          3  \n",
              "2  i dont know although id sure like to talk to h...         22  \n",
              "3                          that life is worth living          5  \n",
              "4  the polls will be open from now until the end ...         33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5ac5b55-c83b-4387-81e9-e9b57ca67fce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>number</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>timestamp_in_ms</th>\n",
              "      <th>speaking_line</th>\n",
              "      <th>character_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>raw_location_text</th>\n",
              "      <th>spoken_words</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9549</td>\n",
              "      <td>32</td>\n",
              "      <td>209</td>\n",
              "      <td>Miss Hoover: No, actually, it was a little of ...</td>\n",
              "      <td>848000</td>\n",
              "      <td>True</td>\n",
              "      <td>464.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>No, actually, it was a little of both. Sometim...</td>\n",
              "      <td>no actually it was a little of both sometimes ...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9550</td>\n",
              "      <td>32</td>\n",
              "      <td>210</td>\n",
              "      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n",
              "      <td>856000</td>\n",
              "      <td>True</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>Where's Mr. Bergstrom?</td>\n",
              "      <td>wheres mr bergstrom</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9551</td>\n",
              "      <td>32</td>\n",
              "      <td>211</td>\n",
              "      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n",
              "      <td>856000</td>\n",
              "      <td>True</td>\n",
              "      <td>464.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
              "      <td>i dont know although id sure like to talk to h...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9552</td>\n",
              "      <td>32</td>\n",
              "      <td>212</td>\n",
              "      <td>Lisa Simpson: That life is worth living.</td>\n",
              "      <td>864000</td>\n",
              "      <td>True</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>That life is worth living.</td>\n",
              "      <td>that life is worth living</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9553</td>\n",
              "      <td>32</td>\n",
              "      <td>213</td>\n",
              "      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n",
              "      <td>864000</td>\n",
              "      <td>True</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Edna Krabappel-Flanders</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>The polls will be open from now until the end ...</td>\n",
              "      <td>the polls will be open from now until the end ...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5ac5b55-c83b-4387-81e9-e9b57ca67fce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5ac5b55-c83b-4387-81e9-e9b57ca67fce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5ac5b55-c83b-4387-81e9-e9b57ca67fce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a416afee-9f29-4855-ac0f-1d347a1957b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a416afee-9f29-4855-ac0f-1d347a1957b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a416afee-9f29-4855-ac0f-1d347a1957b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df = pd.read_csv('simpsons_script_lines.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "QWf4_E4HljBJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L1j5zeIPX6Vb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "fd2154e8-f884-404f-947f-b99a0477f921"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  episode_id  number  \\\n",
              "57  9660          33       5   \n",
              "58  9605          32     265   \n",
              "62  9609          32     269   \n",
              "64  9611          32     271   \n",
              "66  9613          32     273   \n",
              "\n",
              "                                             raw_text timestamp_in_ms  \\\n",
              "57  Homer Simpson: (INDIGNANT) Never thrown a part...           97000   \n",
              "58  Homer Simpson: (MULLING IT OVER, LOW, TO HIMSE...         1070000   \n",
              "62                                 Homer Simpson: Oh.         1086000   \n",
              "64                                Homer Simpson: And?         1088000   \n",
              "66  Homer Simpson: Hey, just because I don't care ...         1091000   \n",
              "\n",
              "   speaking_line character_id  location_id raw_character_text  \\\n",
              "57          True          2.0          5.0      Homer Simpson   \n",
              "58          True          2.0          5.0      Homer Simpson   \n",
              "62          True          2.0          5.0      Homer Simpson   \n",
              "64          True          2.0          5.0      Homer Simpson   \n",
              "66          True          2.0          5.0      Homer Simpson   \n",
              "\n",
              "   raw_location_text                                       spoken_words  \\\n",
              "57      Simpson Home  Never thrown a party? What about that big bash...   \n",
              "58      Simpson Home  Bart didn't get one vote?! Oh, this is the wor...   \n",
              "62      Simpson Home                                                Oh.   \n",
              "64      Simpson Home                                               And?   \n",
              "66      Simpson Home  Hey, just because I don't care doesn't mean I ...   \n",
              "\n",
              "                                      normalized_text word_count  \n",
              "57  never thrown a party what about that big bash ...         22  \n",
              "58  bart didnt get one vote oh this is the worst t...         30  \n",
              "62                                                 oh          1  \n",
              "64                                                and          1  \n",
              "66  hey just because i dont care doesnt mean i don...         11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b33c6a57-37f8-46ae-a57a-c683ee9429b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>number</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>timestamp_in_ms</th>\n",
              "      <th>speaking_line</th>\n",
              "      <th>character_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>raw_location_text</th>\n",
              "      <th>spoken_words</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>9660</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>Homer Simpson: (INDIGNANT) Never thrown a part...</td>\n",
              "      <td>97000</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>Never thrown a party? What about that big bash...</td>\n",
              "      <td>never thrown a party what about that big bash ...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>9605</td>\n",
              "      <td>32</td>\n",
              "      <td>265</td>\n",
              "      <td>Homer Simpson: (MULLING IT OVER, LOW, TO HIMSE...</td>\n",
              "      <td>1070000</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>Bart didn't get one vote?! Oh, this is the wor...</td>\n",
              "      <td>bart didnt get one vote oh this is the worst t...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>9609</td>\n",
              "      <td>32</td>\n",
              "      <td>269</td>\n",
              "      <td>Homer Simpson: Oh.</td>\n",
              "      <td>1086000</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>Oh.</td>\n",
              "      <td>oh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>9611</td>\n",
              "      <td>32</td>\n",
              "      <td>271</td>\n",
              "      <td>Homer Simpson: And?</td>\n",
              "      <td>1088000</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>And?</td>\n",
              "      <td>and</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>9613</td>\n",
              "      <td>32</td>\n",
              "      <td>273</td>\n",
              "      <td>Homer Simpson: Hey, just because I don't care ...</td>\n",
              "      <td>1091000</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>Hey, just because I don't care doesn't mean I ...</td>\n",
              "      <td>hey just because i dont care doesnt mean i don...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b33c6a57-37f8-46ae-a57a-c683ee9429b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b33c6a57-37f8-46ae-a57a-c683ee9429b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b33c6a57-37f8-46ae-a57a-c683ee9429b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e93b1c63-05cb-4338-84e4-a74e994e579d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e93b1c63-05cb-4338-84e4-a74e994e579d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e93b1c63-05cb-4338-84e4-a74e994e579d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_Homer",
              "summary": "{\n  \"name\": \"df_Homer\",\n  \"rows\": 29842,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45496,\n        \"min\": 4,\n        \"max\": 158309,\n        \"num_unique_values\": 29842,\n        \"samples\": [\n          65870,\n          83966,\n          239\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 162,\n        \"min\": 1,\n        \"max\": 568,\n        \"num_unique_values\": 564,\n        \"samples\": [\n          7,\n          558,\n          266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84,\n        \"min\": 0,\n        \"max\": 391,\n        \"num_unique_values\": 372,\n        \"samples\": [\n          230,\n          14,\n          291\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27698,\n        \"samples\": [\n          \"Homer Simpson: Marge, kids, let's go buy some happiness!\",\n          \"Homer Simpson: Whatever.\",\n          \"Homer Simpson: (SULKY) When I'm sad, I make baseball bats.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp_in_ms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2581,\n        \"samples\": [\n          561000,\n          \"1067000\",\n          661000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaking_line\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          false,\n          \"false\",\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"character_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2\",\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1151.3588221221587,\n        \"min\": 1.0,\n        \"max\": 4457.0,\n        \"num_unique_values\": 2157,\n        \"samples\": [\n          1868.0,\n          3627.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_character_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Homer Simpson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_location_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2168,\n        \"samples\": [\n          \"Paris\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spoken_words\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26032,\n        \"samples\": [\n          \"But I have to get back to Marge.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25585,\n        \"samples\": [\n          \"well then you might as well stay with us we serve the same meat the prisons do\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"77\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_Homer = df[df['raw_character_text'] == 'Homer Simpson']\n",
        "df_Homer.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lgxpYU_wYbf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dba09bb-36e6-468c-da19-5146a6e48cb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Never thrown a party? What about that big bash...\n",
              "1    Bart didn't get one vote?! Oh, this is the wor...\n",
              "2                                                  Oh.\n",
              "3                                                 And?\n",
              "4    Hey, just because I don't care doesn't mean I ...\n",
              "Name: spoken_words, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_Homer_spoken_words = df_Homer['spoken_words'].reset_index(drop=True)\n",
        "df_Homer_spoken_words.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Homer_spoken_words[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DOqtMSospAvR",
        "outputId": "c5d8509b-7f5f-4499-9246-a8b2b36f7930"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Never thrown a party? What about that big bash we had with all the champagne and musicians and holy men and everything?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_Homer_spoken_words[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-3TgzDypgnE",
        "outputId": "5e030eb1-5313-4234-e7c5-86c278b81f7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Homer_spoken_words[54], type(df_Homer_spoken_words[54])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XynFsg-ip4cK",
        "outputId": "a744f88a-1718-4476-bbc8-5552c076703d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(nan, float)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Homer_str = []\n",
        "l = len(df_Homer_spoken_words)\n",
        "for i in range(l):\n",
        "  Homer_str.append(str(df_Homer_spoken_words[i]))\n",
        "print(len(Homer_str))\n",
        "Homer_str = \"\\n\".join(Homer_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN2cZ3gZmTsi",
        "outputId": "c3ec326a-96eb-4dda-8671-d3e99aebb4d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ao7G041KZIfi",
        "outputId": "1b7dcf71-5224-4419-ed27-5b11e907fb26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.series.Series</b><br/>def __init__(data=None, index=None, dtype: Dtype | None=None, name=None, copy: bool | None=None, fastpath: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/series.py</a>One-dimensional ndarray with axis labels (including time series).\n",
              "\n",
              "Labels need not be unique but must be a hashable type. The object\n",
              "supports both integer- and label-based indexing and provides a host of\n",
              "methods for performing operations involving the index. Statistical\n",
              "methods from ndarray have been overridden to automatically exclude\n",
              "missing data (currently represented as NaN).\n",
              "\n",
              "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
              "associated index values-- they need not be the same length. The result\n",
              "index will be the sorted union of the two indexes.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : array-like, Iterable, dict, or scalar value\n",
              "    Contains data stored in Series. If data is a dict, argument order is\n",
              "    maintained.\n",
              "index : array-like or Index (1d)\n",
              "    Values must be hashable and have the same length as `data`.\n",
              "    Non-unique index values are allowed. Will default to\n",
              "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
              "    and index is None, then the keys in the data are used as the index. If the\n",
              "    index is not None, the resulting Series is reindexed with the index values.\n",
              "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
              "    Data type for the output Series. If not specified, this will be\n",
              "    inferred from `data`.\n",
              "    See the :ref:`user guide &lt;basics.dtypes&gt;` for more usages.\n",
              "name : Hashable, default None\n",
              "    The name to give to the Series.\n",
              "copy : bool, default False\n",
              "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.series&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing Series from a dictionary with an Index specified\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "a   1\n",
              "b   2\n",
              "c   3\n",
              "dtype: int64\n",
              "\n",
              "The keys of the dictionary match with the Index values, hence the Index\n",
              "values have no effect.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "x   NaN\n",
              "y   NaN\n",
              "z   NaN\n",
              "dtype: float64\n",
              "\n",
              "Note that the Index is first build with the keys from the dictionary.\n",
              "After this the Series is reindexed with the given Index values, hence we\n",
              "get all NaN as a result.\n",
              "\n",
              "Constructing Series from a list with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = [1, 2]\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "[1, 2]\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `copy` of\n",
              "the original data even though `copy=False`, so\n",
              "the data is unchanged.\n",
              "\n",
              "Constructing Series from a 1d ndarray with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = np.array([1, 2])\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "array([999,   2])\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `view` on\n",
              "the original data, so\n",
              "the data is changed as well.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 244);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "type(df_Homer_spoken_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Homer_str[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRMxxt8DoVzm",
        "outputId": "b7c984b7-2758-4269-ccda-25b8b941a81d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Never thrown a party? What about that big bash we had with all the champagne and musicians and holy men and everything?\n",
            "Bart didn't get one vote?! Oh, this is the worst thing that ever happened to us. Alright, allright, spilled milk, spilled milk, spilled milk. What are you so mopey about?\n",
            "Oh.\n",
            "And?\n",
            "Hey, just because I don't care doesn't mean I don't understand.\n",
            "Me?\n",
            "I don't think you realize what you're saying.\n",
            "Did you hear that, Marge? She called me a baboon! The stupidest, ugliest, smelliest ape of them all!\n",
            "Go Away.\n",
            "Lisa, don't hold anything back. You can tell me. Are you crying because you called Daddy a baboon?\n",
            "Nuts.\n",
            "This isn't going well at all.\n",
            "No, no, no. I just wish I knew what to say.\n",
            "Although, maybe this will help. Now you lost someone special and it hurts. I'm lucky because I never lost anyone special to me. Everyone special to me is under this roof.\n",
            "Oh.\n",
            "It's true. Now, you'll have lots of special people in your life, Lisa. There's probably some place where they all get toge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RZpVMTIQZZo0"
      },
      "outputs": [],
      "source": [
        "# Homer_spoken_words_str = df_Homer_spoken_words.to_string(index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VDGFjoB6ZhRs",
        "outputId": "03deaa1c-f51b-4401-8a5b-8199b7de1039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Never thrown a party? What about that big bash we had with all the champagne and musicians and holy men and everything?\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Bart didn't get one vote?! Oh, this is the worst thing that ever happened to us. Alright, allright, spilled milk, spilled milk, spilled milk. What are you so mopey about?\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Oh.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Homer_spoken_words_str[:4020]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdUA242WaAVc",
        "outputId": "e155af20-e19f-4392-963b-e3e145f7dcaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32080149"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# len(Homer_spoken_words_str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Homer_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUBuSU5wqvGp",
        "outputId": "1b72b42d-d2fc-493f-a052-953ef698676e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1469823"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Homer_str[-1000:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKOqYdM3q0S-",
        "outputId": "25c15c79-df0e-457e-d5b4-550c5f828581"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " it because... you're trapped. If you were smarter, you might think of something, but you're not so you just might as well... all right! All right! I'll take her. Lousy brain.\n",
            "Hey, what do you mean by, \"Suggested Donation\"?\n",
            "And what if I \"wish\" to pay zero?\n",
            "Oooh, so it's up to me, is it?\n",
            "I see, and you think that people are gonna pay you four dollars and fifty cents, even though they don't have to, just out of the goodness of their... Well, anything you say! Good luck, lady! You're gonna need it!\n",
            "Hey! You don't have to pay! Read the sign!\n",
            "Ohh, pretty creepy. Still, I'd rather have him chasing me than of the Wolf Man.\n",
            "She said that?\n",
            "But you can tell, right? She looks around and sees everybody else's dad with a good education, youthful looks and a clean credit record and thinks, \"Why me? What did I do to deserve this fat old piece of -- \"\n",
            "Well, if she's so wonderful, give her an A.\n",
            "Great. But don't tell her it was a favor to me. Tell her she earned it.\n",
            "You are smooth. I'll give you that.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Homer_spoken_words[29834]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OrknVPc6rFQk",
        "outputId": "3cb6b00d-9bcc-41a9-9cf0-ec26fcd8ea18"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I see, and you think that people are gonna pay you four dollars and fifty cents, even though they don't have to, just out of the goodness of their... Well, anything you say! Good luck, lady! You're gonna need it!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-li6v5__aPHn",
        "outputId": "8b20a84f-6917-4b14-ea4a-88fe1c99b1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 424848 tokens\n"
          ]
        }
      ],
      "source": [
        "Homer_tokens = enc.encode(Homer_str)\n",
        "Homer_tokens = torch.tensor(Homer_tokens)\n",
        "print(f\"loaded {len(Homer_tokens)} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZWhpxyuonVp",
        "outputId": "e0796d43-7621-4a4b-849e-91f50840458c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3211837"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(torch.tensor(enc.encode(df['raw_text'].reset_index(drop=True).to_string(index=False))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk44uOsIyodZ",
        "outputId": "a1e97a9d-e794-4b3c-fadd-156587a90e09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Miss Hoover: No, actually, it was a little of ...\n",
              "1         Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?\n",
              "2         Miss Hoover: I don't know. Although I'd sure l...\n",
              "3                  Lisa Simpson: That life is worth living.\n",
              "4         Edna Krabappel-Flanders: The polls will be ope...\n",
              "                                ...                        \n",
              "158266         Miss Hoover: (OFF LISA'S REACTION) I'm back.\n",
              "158267    Miss Hoover: You see, class, my Lyme disease t...\n",
              "158268                      Miss Hoover: Psy-cho-so-ma-tic.\n",
              "158269         Ralph Wiggum: Does that mean you were crazy?\n",
              "158270             JANEY: No, that means she was faking it.\n",
              "Name: raw_text, Length: 158271, dtype: object"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['raw_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAdLLCkv0raZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf3gFqza0tyv",
        "outputId": "cc11ee5d-1a3b-4cc7-ad9e-c94f758a9f88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                        Miss Hoover: No, actually, it was a little of both. Sometimes when a disease is in all the magazines and all the news shows, it's only natural that you think you have it.\n",
              "1                                                                                                                                                                 Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?\n",
              "2                                                                                          Miss Hoover: I don't know. Although I'd sure like to talk to him. He didn't touch my lesson plan. What did he teach you?\n",
              "3                                                                                                                                                                          Lisa Simpson: That life is worth living.\n",
              "4         Edna Krabappel-Flanders: The polls will be open from now until the end of recess. Now, (SOUR) just in case any of you have decided to put any thought into this, we'll have our final statements. Martin?\n",
              "                                                                                                            ...                                                                                                    \n",
              "158266                                                                                                                                                                 Miss Hoover: (OFF LISA'S REACTION) I'm back.\n",
              "158267                                                                                                                                             Miss Hoover: You see, class, my Lyme disease turned out to be...\n",
              "158268                                                                                                                                                                              Miss Hoover: Psy-cho-so-ma-tic.\n",
              "158269                                                                                                                                                                 Ralph Wiggum: Does that mean you were crazy?\n",
              "158270                                                                                                                                                                     JANEY: No, that means she was faking it.\n",
              "Name: raw_text, Length: 158271, dtype: object"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['raw_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "PuqkGmJiyzk2",
        "outputId": "108e86c4-a09a-49a6-ca50-a79eaeb36857"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Miss Hoover: No, actually, it was a little of both. Sometimes when a disease is in all the magazines and all the news shows, it's only natural that you think you have it.\\n                                                                                                                                                                                                                                                                                                     \""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['raw_text'].reset_index(drop=True).to_string(index=False)[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzxfnNPQ1Njh",
        "outputId": "1902abf0-c53a-407f-af81-b219ad970b53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "103982729"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(torch.tensor(enc.encode(df['raw_text'].reset_index(drop=True).to_string(index=False))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "42be0c5842bd4e3492fc17d7ba98a4b2",
            "cee0a55f5817436b8ab8a605ff2d09bf",
            "cb47deb852874e768090f0c8fd20dadf",
            "86855a8aaa9a441e84ec5a145e97cb2f",
            "6cc63dc3608149dcb61162ac87ce7e9a",
            "cac01b5330164ba9bc9b82ce2fec1ff7",
            "6fc26c7533114cf08afa39a1b9833e5d",
            "5c5b62a1b7664b48a9d27ce28ef62f2e",
            "cdc9354723824e848d8057fd1883f0b9",
            "8ce1f8bf0555432cb663ce8fb00d0650",
            "f8c4c61c06da4b089c6b49003dd55704",
            "d71bb56039f041a5a2f1bc1b2cd590ea",
            "df4789deede24258847c79f71907b9e8",
            "5e56477ce6ae4d8f834042cc8411e7e3",
            "a1a728b8e4b74ea8865e8c51d98f283d",
            "38bf219992464b62a93bedffd55c9f9e",
            "bf025bdcbff9425f8f2b9f8c2040b173",
            "a0ccd34d18da4c4dafaca8496f4c4f4d",
            "64c4c8f924af48298bc27cbfb0e3ff13",
            "4b1ff5cd4661481cb01873df81001b76",
            "adeecd4fd28748558d3986cffbaea0ca",
            "6ceff96e1a5c49c9a7edf882326f0070",
            "dd61d64c5af94fc796f9c918a37b09e9",
            "e14ef9f0b55246838523137b9e9a3ddd",
            "6b1e127b1cd84a8eb416e11832372e01",
            "b0a80b7561fb47c19c81f84e2b08e10d",
            "18b391beb4b74a04b4c4e2344fb725fa",
            "f6dba4722226443e8596ac438a139a77",
            "8bd222aed2304c7cbad37fc438e68ef9",
            "fc3ba93be2fc421ca235f0cec80dfc4a",
            "b8cd4f6503324588a61ce5f3ab5f9279",
            "9e352456322a40eabbe8331a721007ba",
            "e318b24efd584ed5a0282da0bbaedb4f"
          ]
        },
        "id": "P6RVUQX97Zc6",
        "outputId": "dbee2153-2d39-45ac-fb8b-a0a713351b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n",
            "total desired batch size: 524288\n",
            "=> calculated gradient accumulation steps: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-0c07922334fb>:215: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('simpsons_script_lines.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 339878 tokens, ? 339878\n",
            "1 epoch = 20 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-0c07922334fb>:215: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('simpsons_script_lines.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 84970 tokens, ? 339878\n",
            "1 epoch = 5 batches\n",
            "loading weights from pretrained gpt: gpt2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42be0c5842bd4e3492fc17d7ba98a4b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d71bb56039f041a5a2f1bc1b2cd590ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd61d64c5af94fc796f9c918a37b09e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num decayed parameter tensors: 50, with 124,318,464 parameters\n",
            "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
            "using fused AdamW: True\n",
            "step     0 | loss: 3.479502 | lr 6.0000e-05 | norm: 6.0539 | dt: 45808.50ms | tok/sec: 11445.21\n",
            "step     1 | loss: 3.507742 | lr 1.2000e-04 | norm: 7.7489 | dt: 4343.51ms | tok/sec: 120705.99\n",
            "step     2 | loss: 3.391375 | lr 1.8000e-04 | norm: 4.0651 | dt: 4351.36ms | tok/sec: 120488.21\n",
            "step     3 | loss: 3.369171 | lr 2.4000e-04 | norm: 6.9216 | dt: 4355.65ms | tok/sec: 120369.63\n",
            "step     4 | loss: 3.349524 | lr 3.0000e-04 | norm: 4.7948 | dt: 4359.86ms | tok/sec: 120253.27\n",
            "validation loss: 3.4071\n",
            "> Hello, this is Homer Simpson, and I just got to do my usual role that I usually do as a TV show writer. So you have to work out the details.\n",
            "Marge!\n",
            "Now, I want you to get up, please!\n",
            "You! That's my husband!\n",
            "Yeah, I'm kidding! And he says he\n",
            "> Hello, this is Homer Simpson, we love you.\n",
            "So this really is my place to go for tea with my wife. I hope you're enjoying it.\n",
            "Marge: Are you okay?\n",
            "Marge: Do you still feel some sadness in your eyes?\n",
            "Hey, I'm in the middle of cooking!\n",
            "What's the\n",
            "> Hello, this is Homer Simpson, the man who brought you up. Just like my boss. It has become a daily occurrence to me.\n",
            "Hmmm, I'm a little surprised to discover that my first job as a waitress would be to prepare my steak for breakfast.\n",
            "You know who I am. I'm the master sushi chef. My\n",
            "> Hello, this is Homer Simpson, my guy.\n",
            "I'm sorry, Mr. Burns. I got my job without paying your taxes.\n",
            "The truth is that I'm never ever gonna pay you any money. I don't wanna pay you that way.\n",
            "But you're gonna pay me $100 a month. And I'm not gonna be\n",
            "step     5 | loss: 3.271692 | lr 3.6000e-04 | norm: 4.4209 | dt: 41011.55ms | tok/sec: 12783.91\n",
            "step     6 | loss: 3.271192 | lr 4.2000e-04 | norm: 4.1376 | dt: 4348.09ms | tok/sec: 120579.02\n",
            "step     7 | loss: 3.211916 | lr 4.8000e-04 | norm: 2.2854 | dt: 4356.51ms | tok/sec: 120345.84\n",
            "step     8 | loss: 3.156768 | lr 5.4000e-04 | norm: 2.6148 | dt: 4360.89ms | tok/sec: 120224.87\n",
            "step     9 | loss: 3.132669 | lr 6.0000e-04 | norm: 3.3416 | dt: 4362.33ms | tok/sec: 120185.22\n",
            "validation loss: 3.4054\n",
            "> Hello, this is Homer Simpson, the man behind the \"Coca-eyes.\"\n",
            "There you are, Marge.\n",
            "\"Moe, Lisa, Lisa.\"\n",
            "Wait, who is that?\n",
            "I am Lisa Simpson, the father of \"Moe\", my daughter!\n",
            "I am Lisa Simpson, the father of Moe!\n",
            "Yeah\n",
            "> Hello, this is Homer Simpson, and now I'm gonna try and run. And here's a sign.\n",
            "Oh yeah, the new movie.\n",
            "Homer Simpson? A little bird that wants to go for a walk?\n",
            "The only thing that makes my day is how big my smile is.\n",
            "I'll remember this day as the greatest\n",
            "> Hello, this is Homer Simpson, and I get it. There's something I have to tell everyone in the world.\n",
            "Marge, I've been looking for you.\n",
            "I'm so sorry. I'm sorry I ever lied to you.\n",
            "Lisa, there's a man who wants to spend the rest of his life inside your car --\n",
            "> Hello, this is Homer Simpson, I swear.\n",
            "nan\n",
            "I bet the children of Springfield are watching you, in their way.\n",
            "nan\n",
            "Woo-hoo! Your sweet little homecoming party.\n",
            "\"Woo-hoo!\"\n",
            "\"Woo-hoo!\"\n",
            "I bet the rich people of Springfield will see the\n",
            "step    10 | loss: 3.034843 | lr 6.0000e-04 | norm: 2.5885 | dt: 5861.44ms | tok/sec: 89446.89\n",
            "step    11 | loss: 2.997710 | lr 5.9917e-04 | norm: 2.0702 | dt: 4364.67ms | tok/sec: 120121.01\n",
            "step    12 | loss: 2.926883 | lr 5.9668e-04 | norm: 2.5840 | dt: 4366.25ms | tok/sec: 120077.31\n",
            "step    13 | loss: 2.858036 | lr 5.9254e-04 | norm: 1.2471 | dt: 4365.15ms | tok/sec: 120107.72\n",
            "step    14 | loss: 2.833398 | lr 5.8679e-04 | norm: 1.5233 | dt: 4363.33ms | tok/sec: 120157.79\n",
            "validation loss: 3.4025\n",
            "> Hello, this is Homer Simpson, the man whose name is Smithers.\n",
            "He's got three other friends. They're on their way to Vegas!\n",
            "Oh, Smithers!\n",
            "Okay, let's say you get lost and don't find any snakes or frogs around.\n",
            "But what if I hadn't been on my knees?\n",
            "> Hello, this is Homer Simpson, and when I say \"I,\" I mean the head.\"\n",
            "You go! You go! You go!\n",
            "Marge, you've ruined a vacation for me.\n",
            "nan\n",
            "I came here to eat breakfast, but then I found something rotten.\n",
            "Marge, you've ruined a vacation for me.\n",
            "> Hello, this is Homer Simpson, and I hate the nickname.\n",
            "Hey, wait a minute before you ask me which team is the best. I wouldn't mind if you did.\n",
            "Okay, that's it! I'm ready for the new season. From now on, I'll keep my guns to myself.\n",
            "Lumberjack -- what\n",
            "> Hello, this is Homer Simpson, who did it.\n",
            "Hey! We got back to the road!\n",
            "Oh Lord, where are you guys?! My car is too far! Just keep going. You may hear the squeaking sounds of my truck as it goes by!\n",
            "Oh, this is so much better than my car. I was driving\n",
            "step    15 | loss: 2.736091 | lr 5.7945e-04 | norm: 1.0738 | dt: 5830.41ms | tok/sec: 89923.03\n",
            "step    16 | loss: 2.701636 | lr 5.7057e-04 | norm: 1.8551 | dt: 4372.96ms | tok/sec: 119893.11\n",
            "step    17 | loss: 2.626925 | lr 5.6021e-04 | norm: 1.1081 | dt: 4369.23ms | tok/sec: 119995.65\n",
            "step    18 | loss: 2.557845 | lr 5.4843e-04 | norm: 1.2248 | dt: 4370.83ms | tok/sec: 119951.59\n",
            "step    19 | loss: 2.517942 | lr 5.3531e-04 | norm: 1.8196 | dt: 4369.32ms | tok/sec: 119993.00\n",
            "validation loss: 3.5709\n",
            "> Hello, this is Homer Simpson, the man behind the \"Make America Great Again\" bumper stickers. So listen...\n",
            "nan\n",
            "What the Hell is he saying?\n",
            "Woo!\n",
            "Hello, Bart.\n",
            "Woo! Bart! You have a great day. Let's get to the real work.\n",
            "\"All the women want that piece\n",
            "> Hello, this is Homer Simpson, and I'm trying to read your words. But he really was right when he said I'd be at home reading your words.\n",
            "Oh right! With my finger!\n",
            "Hey, I missed a trip!\n",
            "Apu, what're you thinkin' about?\n",
            "Oh. C'mon, who wants\n",
            "> Hello, this is Homer Simpson, and I came to this hotel to spend some quality time with friends...\n",
            "I'd like to apologize for my behavior, but I don't know what to do.\n",
            "It's a shame I haven't been married to you, Bart.\n",
            "It was about twenty years ago...\n",
            "nan\n",
            "Ah, sweet sweet\n",
            "> Hello, this is Homer Simpson, the little guy!\n",
            "Hmmm, that...\n",
            "Huh?\n",
            "Hey, Bart, do you wanna see my house? I want to see Maggie and Barney. And, uh... one of us, the kids.\n",
            "Hey, where's my car?\n",
            "Oh.\n",
            "Wow!\n",
            "nan\n",
            "Homer\n",
            "step    20 | loss: 2.432817 | lr 5.2092e-04 | norm: 1.6365 | dt: 5840.99ms | tok/sec: 89760.11\n",
            "step    21 | loss: 2.363155 | lr 5.0535e-04 | norm: 0.8380 | dt: 4369.76ms | tok/sec: 119981.06\n",
            "step    22 | loss: 2.304949 | lr 4.8870e-04 | norm: 1.8335 | dt: 4372.14ms | tok/sec: 119915.70\n",
            "step    23 | loss: 2.231796 | lr 4.7107e-04 | norm: 1.0204 | dt: 4367.87ms | tok/sec: 120032.83\n",
            "step    24 | loss: 2.173363 | lr 4.5258e-04 | norm: 0.8681 | dt: 4372.31ms | tok/sec: 119910.97\n",
            "validation loss: 3.9141\n",
            "> Hello, this is Homer Simpson, the man of the hour. The patriarch of Springfield.\n",
            "You said all this, Bart. It is not your fault, it is not your father's fault, it is not your brother's. That man... is dead. Why, you...\n",
            "nan\n",
            "He's dead!\n",
            "nan\n",
            "He is!\n",
            "> Hello, this is Homer Simpson, and I'm trying to say a highly-polished pork chop breakfast sandwich from a lifetime of being snub-nosed is just as good as it's gonna get.\n",
            "Sorry, Captain.\n",
            "Marge, you and your little guy ate at the Springfield Nuclear Power Plant, and it was one of those\n",
            "> Hello, this is Homer Simpson, and I thought we were doing a mini-vlog. Anyway, here's something for everybody.\n",
            "I don't know. Maybe this is the greatest day of my life. And I'm never gonna tire of showing you guys how to cook.\n",
            "How much oil? How much butter? Can I get it\n",
            "> Hello, this is Homer Simpson, the real deal.\n",
            "nan\n",
            "And you two are Homer Simpson and you don't belong to him.\n",
            "Oh gee... what if I threw out the last one?\n",
            "This ain't easy.\n",
            "And this is Homer Simpson saying I'm not allowed in his restaurant.\n",
            "nan\n",
            "Hey! What happened\n",
            "step    25 | loss: 2.089298 | lr 4.3332e-04 | norm: 1.0708 | dt: 5867.74ms | tok/sec: 89350.89\n",
            "step    26 | loss: 2.018292 | lr 4.1343e-04 | norm: 0.9323 | dt: 4366.79ms | tok/sec: 120062.45\n",
            "step    27 | loss: 1.957597 | lr 3.9303e-04 | norm: 0.9215 | dt: 4371.21ms | tok/sec: 119941.18\n",
            "step    28 | loss: 1.876682 | lr 3.7224e-04 | norm: 0.9044 | dt: 4371.34ms | tok/sec: 119937.67\n",
            "step    29 | loss: 1.831435 | lr 3.5118e-04 | norm: 1.4279 | dt: 4370.21ms | tok/sec: 119968.63\n",
            "validation loss: 4.2372\n",
            "> Hello, this is Homer Simpson, the \"Fonz,\" harassing his customers. Who are you?\n",
            "This is the \"Fonz,\" harassing my customers.\n",
            "Oh, please don't hassle me again.\n",
            "Hmmm. It could've been me. Or something very strange happened.\n",
            "What did he do?\n",
            "What a beautiful woman.\n",
            "> Hello, this is Homer Simpson, my best friend in law. You hear me?! Aha! Now you have my wife. Now you have my son.\n",
            "Well... Bart! Help me save my wife! Oh, yes!\n",
            "Bart!\n",
            "Look, you and his mother are doing great. You're dating my best friend, the\n",
            "> Hello, this is Homer Simpson, and I'm gonna play Dungeons and Dragons. That's me telling my son what to do.\n",
            "Gee, thanks, Marge.\n",
            "I thought it would be fun to be your tutor during the early hours of the afternoon.\n",
            "I don't see any reason not to.\n",
            "Hello -- how do you\n",
            "> Hello, this is Homer Simpson, the new Pope.\n",
            "Mmm. Cheap knickknack.\n",
            "Hey, Marge! Tell me everything about you little...\n",
            "Wait a minute. How could I... Damn this church awful!\n",
            "Why? Why did I come here?\n",
            "Oh, it's just your little hands. You keep '\n",
            "step    30 | loss: 1.766434 | lr 3.3000e-04 | norm: 1.4555 | dt: 5859.00ms | tok/sec: 89484.22\n",
            "step    31 | loss: 1.694123 | lr 3.0882e-04 | norm: 0.9280 | dt: 4370.94ms | tok/sec: 119948.70\n",
            "step    32 | loss: 1.661318 | lr 2.8776e-04 | norm: 2.0227 | dt: 4370.02ms | tok/sec: 119973.77\n",
            "step    33 | loss: 1.588124 | lr 2.6697e-04 | norm: 1.0583 | dt: 4370.94ms | tok/sec: 119948.50\n",
            "step    34 | loss: 1.556650 | lr 2.4657e-04 | norm: 1.5259 | dt: 4371.55ms | tok/sec: 119931.80\n",
            "validation loss: 4.6184\n",
            "> Hello, this is Homer Simpson, the father of the kids. Well, there's some trouble I couldn't handle. Homer, get in here!\n",
            "We'll see about that, Flanders.\n",
            "No, he got in some trouble and I'm sure he'll come down here to help me.\n",
            "I'm taking care of him!\n",
            "\n",
            "> Hello, this is Homer Simpson, my knight in white coat. How could you... Aw, I wish I knew how this works. Stupid questions.\n",
            "Hello, everybody! Where is Diaper to Sleep? Where is Milk to Dry Head? Where is... Uh-oh. And what's that?\n",
            "I don't want to! I want\n",
            "> Hello, this is Homer Simpson, my favorite nerd!\n",
            "Yeah, it's pretty awesome. Look out for the rocket ship!\n",
            "Whoa! Here, let me throw the rocket ship!\n",
            "It was a construction site! That must be why it's glowing!\n",
            "nan\n",
            "Huh?\n",
            "Don't tell me where to begin.\n",
            "What\n",
            "> Hello, this is Homer Simpson, the Rock Strongest Man of All-time. I'm gonna save you money.\n",
            "And that's why we bought it!\n",
            "Well, who knew that a Christmas tree could be that useful to you? Just slide it over your Christmas tree and you're all set to do the work of a real sleigh\n",
            "step    35 | loss: 1.513962 | lr 2.2668e-04 | norm: 1.2016 | dt: 5864.97ms | tok/sec: 89393.14\n",
            "step    36 | loss: 1.447473 | lr 2.0742e-04 | norm: 0.9775 | dt: 4370.77ms | tok/sec: 119953.27\n",
            "step    37 | loss: 1.421162 | lr 1.8893e-04 | norm: 0.9717 | dt: 4369.36ms | tok/sec: 119991.94\n",
            "step    38 | loss: 1.367818 | lr 1.7130e-04 | norm: 0.7423 | dt: 4374.28ms | tok/sec: 119856.99\n",
            "step    39 | loss: 1.339776 | lr 1.5465e-04 | norm: 0.6793 | dt: 4371.97ms | tok/sec: 119920.35\n",
            "validation loss: 4.9316\n",
            "> Hello, this is Homer Simpson, the \"Superdad.\" That's me!\n",
            "And I'm so bulgy!\n",
            "Really? That's what women think?! Well, really thinkin'.\n",
            "Really?\n",
            "Homer Simpson's doing this?\n",
            "He said do this!\n",
            "So, you want a piece of me? Marge and Homer\n",
            "> Hello, this is Homer Simpson, the American dream's finally being crushed under a sea of cheap plastic surgery.\n",
            "Oh my God! And it's so beautiful! I wish I'd never been born!\n",
            "nan\n",
            "I wanna try it on now, baby.\n",
            "It's all here.\n",
            "And it feels so good.\n",
            "And it's\n",
            "> Hello, this is Homer Simpson, my good man. Can you come and get me a divorce billable?\n",
            "Uh... yes, sir.\n",
            "Bart!\n",
            "This is the luckiest thing I've ever seen.\n",
            "Uh... yes, sir.\n",
            "No, I got the piece I needed.\n",
            "Hey, Lenny! Let's\n",
            "> Hello, this is Homer Simpson, the World's Greatest Dad! I'm always giving you directions!\n",
            "Hmmm.\n",
            "Ooh, here's my car!\n",
            "nan\n",
            "But this is my daughter, the world's greatest child!\n",
            "Why would you make that move?\n",
            "nan\n",
            "That was an expression. I know how people feel when\n",
            "step    40 | loss: 1.311172 | lr 1.3908e-04 | norm: 0.7696 | dt: 5858.65ms | tok/sec: 89489.60\n",
            "step    41 | loss: 1.264443 | lr 1.2469e-04 | norm: 0.5924 | dt: 4371.60ms | tok/sec: 119930.42\n",
            "step    42 | loss: 1.247447 | lr 1.1157e-04 | norm: 0.5190 | dt: 4371.32ms | tok/sec: 119938.06\n",
            "step    43 | loss: 1.210703 | lr 9.9787e-05 | norm: 0.5123 | dt: 4372.78ms | tok/sec: 119898.11\n",
            "step    44 | loss: 1.193665 | lr 8.9428e-05 | norm: 0.5140 | dt: 4372.15ms | tok/sec: 119915.46\n",
            "validation loss: 5.0662\n",
            "> Hello, this is Homer Simpson, the \"Bart-maaighty-me\".\n",
            "Well, fine. I'll go pick up my mail.\n",
            "I'm sure you'll like it when I do, so feel free to go check out my place.\n",
            "Uh, yeah.\n",
            "No, no, no, no. It's just\n",
            "> Hello, this is Homer Simpson, the Magical Man from \"Jaws 2\", hiding out in a dark alley behind a dumpster.\n",
            "Well, if you don't like it, something wrong with the government is at work.\n",
            "Ow! Ow! I'll-- Ow! Ow! My back! I'll have to use my back --\n",
            "> Hello, this is Homer Simpson, your father, your uncle... whaddaya think? \"Dad, I want you to take a few trips to the bathroom. First, you have to get the boy's toothbrush, put on the sounds of the teacher's getting more and more weight, put on the squeak-siren sound --\n",
            "> Hello, this is Homer Simpson, the funny guy. But you have to admit it, it's pretty amazing. Even more amazing, than that... Okay, you say Homer Simpson, and I says Moe.\n",
            "The wang stays.\n",
            "Homer Simpson is a wang.\n",
            "Woo hoo! Lisa!\n",
            "Wang! W\n",
            "step    45 | loss: 1.176294 | lr 8.0553e-05 | norm: 0.4103 | dt: 5848.20ms | tok/sec: 89649.47\n",
            "step    46 | loss: 1.141222 | lr 7.3215e-05 | norm: 0.4125 | dt: 4374.57ms | tok/sec: 119849.09\n",
            "step    47 | loss: 1.135064 | lr 6.7460e-05 | norm: 0.4184 | dt: 4374.60ms | tok/sec: 119848.31\n",
            "step    48 | loss: 1.107823 | lr 6.3324e-05 | norm: 0.4007 | dt: 4374.13ms | tok/sec: 119861.12\n",
            "validation loss: 5.1988\n",
            "> Hello, this is Homer Simpson, the father of Springfield, and this is changing chapter to chapter. But first you have to meet Springfield's newest king, Springfield! Springfield, Springfield, Springfield, Springfield!\n",
            "Look, everybody! Springfield and the Krusty will be fine!\n",
            "Ow!\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "> Hello, this is Homer Simpson, the sun up here, the seagulls roamed free in my hat. I mean uh, I'm not totally insane.\n",
            "So... after all these years, where did you get all that hair?\n",
            "I guess it's either here or somewhere far away. Oh, Lisa, I don't want\n",
            "> Hello, this is Homer Simpson, your father, your uncle... Whoa, since you're finally getting to meet people from your old neighborhood, I thought it'd be good to give this imposter a little favor: I want some sugar.\n",
            "Sweetie, it's no good, look. I drained a little bit of portobello and\n",
            "> Hello, this is Homer Simpson, the funny guy but the net befitting him...\n",
            "Hey, if you really think you're gonna mar that flag, you should talk to Grampa.\n",
            "Well, it's still his marimba! That's the kind of stupid talk he gets on Fox.\n",
            "I could live with one lousy game...\n",
            "step    49 | loss: 1.096366 | lr 6.0832e-05 | norm: 0.3573 | dt: 5877.29ms | tok/sec: 89205.79\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import inspect\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "        # regularization\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        # not really a 'bias', more of a mask, but following the OpenAI/HF naming though\n",
        "        # self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "        #                              .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
        "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "        # output projection\n",
        "        y = self.c_proj(y)\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
        "        self.gelu    = nn.GELU(approximate='tanh')\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024 # max sequence length\n",
        "    vocab_size: int = 50257 # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
        "    n_layer: int = 12 # number of layers\n",
        "    n_head: int = 12 # number of heads\n",
        "    n_embd: int = 768 # embedding dimension\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        # weight sharing scheme\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        # init params\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            std = 0.02\n",
        "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
        "                std *= (2 * self.config.n_layer) ** -0.5\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # idx is of shape (B, T)\n",
        "        B, T = idx.size()\n",
        "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "        # forward the token and posisition embeddings\n",
        "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device) # shape (T)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (B, T, n_embd)\n",
        "        x = tok_emb + pos_emb\n",
        "        # forward the blocks of the transformer\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        # forward the final layernorm and the classifier\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "        return logits, loss\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # n_layer, n_head and n_embd are determined from model_type\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
        "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = GPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
        "        # this means that we have to transpose these weights when we import them\n",
        "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                # special treatment for the Conv1D weights we need to transpose\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                # vanilla copy over the other parameters\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, device_type):\n",
        "        # start with all of the candidate parameters (that require grad)\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == \"cuda\"\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, fused=use_fused)\n",
        "        return optimizer\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class DataLoaderLite:\n",
        "    def __init__(self, B, T, split):\n",
        "        self.B = B\n",
        "        self.T = T\n",
        "        assert split in {'train', 'val'}\n",
        "\n",
        "        # at init load tokens from disk and store them in memory\n",
        "        # !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "        # with open('simpsons_script_lines.csv', 'r') as f:\n",
        "            # text = f.read()\n",
        "        df = pd.read_csv('simpsons_script_lines.csv')\n",
        "        df_Homer = df[df['raw_character_text'] == 'Homer Simpson']\n",
        "        # df_text = df['raw_text'].reset_index(drop=True).to_string(index=False)\n",
        "        df_Homer_spoken_words = df_Homer['spoken_words'].reset_index(drop=True)\n",
        "        Homer_str = []\n",
        "        l = len(df_Homer_spoken_words)\n",
        "        for i in range(l):\n",
        "          Homer_str.append(str(df_Homer_spoken_words[i]))\n",
        "        Homer_str = \"\\n\".join(Homer_str)\n",
        "        # Homer_spoken_words_str = df_Homer_spoken_words.to_string(index=False)\n",
        "        # text = Homer_spoken_words_str\n",
        "        text = Homer_str\n",
        "        enc = tiktoken.get_encoding('gpt2')\n",
        "        tokens = enc.encode(text)\n",
        "        l = len(tokens)\n",
        "        if split == 'train':\n",
        "            self.tokens = torch.tensor(tokens[:int(0.8*l)])\n",
        "        elif split == 'val':\n",
        "            self.tokens = torch.tensor(tokens[int(0.8*l):])\n",
        "        # self.tokens = torch.tensor(tokens)\n",
        "        print(f\"loaded {len(self.tokens)} tokens, ? 339878\")\n",
        "        print(f\"1 epoch = {len(self.tokens) // (B * T)} batches\")\n",
        "\n",
        "        # state\n",
        "        self.current_position = 0\n",
        "\n",
        "    def next_batch(self):\n",
        "        B, T = self.B, self.T\n",
        "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
        "        x = (buf[:-1]).view(B, T) # inputs\n",
        "        y = (buf[1:]).view(B, T) # targets\n",
        "        # advance the position in the tensor\n",
        "        self.current_position += B * T\n",
        "        # if loading the next batch would be out of bounds, reset\n",
        "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
        "            self.current_position = 0\n",
        "        return x, y\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# attempt to autodetect the device\n",
        "import time\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "# added after video, pytorch can be serious about it's device vs. device_type distinction\n",
        "device_type = \"cuda\" if device.startswith(\"cuda\") else \"cpu\"\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(1337)\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# total_batch_size = 16777216 # 2**24, 11,135,759, in number of tokens\n",
        "total_batch_size = 524288 # 2**19, 424848 * 0.8 = 339878 in number of Homer_tokens\n",
        "# total_batch_size = 4194304 # 2**22, 3,211,837 in number of tokens\n",
        "# total_batch_size = 134217728 # 2**27, 103,982,729 in number of tokens\n",
        "B = 16 # micro batch size\n",
        "T = 1024 # sequence length\n",
        "assert total_batch_size % (B * T) == 0, \"make sure total_batch_size is divisible by B * T\"\n",
        "grad_accum_steps = total_batch_size // (B * T)\n",
        "print(f\"total desired batch size: {total_batch_size}\")\n",
        "print(f\"=> calculated gradient accumulation steps: {grad_accum_steps}\")\n",
        "\n",
        "train_loader = DataLoaderLite(B=B, T=T, split=\"train\")\n",
        "val_loader = DataLoaderLite(B=B, T=T, split=\"val\")\n",
        "\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# get logits\n",
        "model = GPT.from_pretrained('gpt2')\n",
        "# model = GPT(GPTConfig(vocab_size=50304))\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "# raw_model = model.module if ddp else model # always contains the \"raw\" unwrapped model\n",
        "\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "warmup_steps = 10  # 715\n",
        "max_steps = 50  # 19073\n",
        "\n",
        "def get_lr(it):\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it+1) / warmup_steps\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > max_steps:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
        "    return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "# prefix tokens\n",
        "def generate(model, num_return_sequences = 5, max_length = 70, prompts = \"Hello, this is Homer Simpson,\", log_file = \"log/log.txt\"):\n",
        "    model.eval()\n",
        "    num_return_sequences = num_return_sequences\n",
        "    max_length = max_length\n",
        "    tokens = enc.encode(prompts)\n",
        "    tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
        "    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1) # (5, 8)\n",
        "    x = tokens.to(device)\n",
        "\n",
        "    # generate! right now x is (B, T) where B = 5, T = 8\n",
        "    # set the seed to 42\n",
        "    torch.manual_seed(42)\n",
        "    torch.cuda.manual_seed(42)\n",
        "    while x.size(1) < max_length:\n",
        "        # forward the model to get the logits\n",
        "        with torch.no_grad():\n",
        "            with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
        "                logits, loss = model(x) # (B, T, vocab_size)\n",
        "            # take the logits at the last position\n",
        "            logits = logits[:, -1, :] # (B, vocab_size)\n",
        "            # get the probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # do top-k sampling of 50 (huggingface pipeline default)\n",
        "            # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
        "            topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
        "            # select a token from the top-k probabilities\n",
        "            # note: multinomial does not demand the input to sum to 1\n",
        "            ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
        "            # gather the corresponding indices\n",
        "            xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
        "            # append to the sequence\n",
        "            x = torch.cat((x, xcol), dim=1)\n",
        "\n",
        "    # print the generated text\n",
        "    for i in range(num_return_sequences):\n",
        "        tokens = x[i, :max_length].tolist()\n",
        "        decoded = enc.decode(tokens)\n",
        "        print(\">\", decoded)\n",
        "        with open(log_file, \"a\") as f:\n",
        "            f.write(f\"> {decoded}\\n\")\n",
        "\n",
        "# optimize!\n",
        "optimizer = model.configure_optimizers(weight_decay=0.1, learning_rate=6e-4, device_type=device_type)\n",
        "\n",
        "# create the log directory we will write checkpoints to and log to\n",
        "log_dir = \"log\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "log_file = os.path.join(log_dir, f\"log.txt\")\n",
        "with open(log_file, \"w\") as f: # open for writing to clear the file\n",
        "    pass\n",
        "\n",
        "for step in range(max_steps):\n",
        "    t0 = time.time()\n",
        "    last_step = (step == max_steps - 1)\n",
        "\n",
        "    # once in a while evaluate our validation loss\n",
        "    if (step > 0 and step % 5 == 0) or last_step:\n",
        "        model.eval()\n",
        "        # val_loader.reset()\n",
        "        with torch.no_grad():\n",
        "            val_loss_accum = 0.0\n",
        "            val_loss_steps = 161118 // (B * T)\n",
        "            for _ in range(val_loss_steps):\n",
        "                x, y = val_loader.next_batch()\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
        "                    logits, loss = model(x, y)\n",
        "                loss = loss / val_loss_steps\n",
        "                val_loss_accum += loss.detach()\n",
        "        print(f\"validation loss: {val_loss_accum.item():.4f}\")\n",
        "        with open(log_file, \"a\") as f:\n",
        "            f.write(f\"{step} val {val_loss_accum.item():.4f}\\n\")\n",
        "        if step > 0 and (step % 5 == 0 or last_step):\n",
        "            # optionally write model checkpoints\n",
        "            checkpoint_path = os.path.join(log_dir, f\"model_{step:03d}.pt\")\n",
        "            checkpoint = {\n",
        "                'model': model.state_dict(),\n",
        "                'config': model.config,\n",
        "                'step': step,\n",
        "                'val_loss': val_loss_accum.item()\n",
        "            }\n",
        "            # you might also want to add optimizer.state_dict() and\n",
        "            # rng seeds etc., if you wanted to more exactly resume training\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "        generate(model, num_return_sequences = 4)\n",
        "\n",
        "    # do one step of the optimization\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    loss_accum = 0.0\n",
        "    for micro_step in range(grad_accum_steps):\n",
        "        x, y = train_loader.next_batch()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
        "            logits, loss = model(x, y)\n",
        "        # we have to scale the loss to account for gradient accumulation,\n",
        "        # because the gradients just add on each successive backward().\n",
        "        # addition of gradients corresponds to a SUM in the objective, but\n",
        "        # instead of a SUM we want MEAN. Scale the loss here so it comes out right\n",
        "        loss = loss / grad_accum_steps\n",
        "        loss_accum += loss.detach()\n",
        "        loss.backward()\n",
        "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    # determine and set the learning rate for this iteration\n",
        "    lr = get_lr(step)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    optimizer.step()\n",
        "    if device_type == \"cuda\":\n",
        "        torch.cuda.synchronize() # wait for the GPU to finish work\n",
        "    t1 = time.time()\n",
        "    dt = t1 - t0 # time difference in seconds\n",
        "    tokens_processed = train_loader.B * train_loader.T * grad_accum_steps\n",
        "    tokens_per_sec = tokens_processed / dt\n",
        "    print(f\"step {step:5d} | loss: {loss_accum.item():.6f} | lr {lr:.4e} | norm: {norm:.4f} | dt: {dt*1000:.2f}ms | tok/sec: {tokens_per_sec:.2f}\")\n",
        "    with open(log_file, \"a\") as f:\n",
        "        f.write(f\"{step} train {loss_accum.item():.6f}\\n\")\n",
        "\n",
        "# import sys; sys.exit(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MmBczLl0xwX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e810de2a-f64c-4403-e7c1-79af9af921e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Hello, this is Homer Simpson, the \"Dream Teamee\"!\n",
            "nan\n",
            "No, I want to be Team Homer Simpson!\n",
            "You've got everything you wanted!\n",
            "My car! You're taking everything?!\n",
            "Why you old man, little! I don't care for cars!\n",
            "That's right, a car is bad! And when a dream comes true, it's wicked!\n",
            "Hmmm, a car is something! A car is something that I, as the sum of its\n",
            "> Hello, this is Homer Simpson, the angry, fat old father of five kids... gone!\n",
            "Hey, where's Lisa? Oh, why did I have to tell all these horrible things to make you happy? Oh, why did I have to lie and steal all these funny kids' toys? Oh, I'm sorry, Lisa.\n",
            "Now, Flanders, you don't see many fat old white male celebrities giving their massive public speaking fees to a sham charity.\n",
            "Sorry, Flanders\n",
            "> Hello, this is Homer Simpson, your father, your uncle... whaddaya say? Hello, my beloved.\n",
            "Well, I'm not sure I look good without a suit, but you could do a little work for just a little little little time. Something like that you got over the old law firm you left in and this one with the beach form.\n",
            "Hey, wait a minute, I'm not turning this round. I have something important to tell you.\n",
            "Your uncle Homer\n",
            "> Hello, this is Homer Simpson, the good cop, the bad cop. You probably saw my flashy new hat. You know, my hat, my American flag... Uh-oh.\n",
            "Bart made a scene a while back where he was fighting Judge Judy in a Mexican courtroom. But this is another story.\n",
            "Well, if it isn't Judge... Ohhhh.... Judge... Hey! A Mexican judge!\n",
            "Oh, you're just making it up to me! Judge... Hey! And\n",
            "> Hello, this is Homer Simpson, the greatest cop of all time, and I'm thinking to myself, \"Oh, gee, he sure knoitts these babies...\"\n",
            "Homer Simpson!!\n",
            "What's a \"knockout\"?\n",
            "What's a \"knock-down\"?\n",
            "What, me and my \"bat\" Lisa give this rapping buddy a standing o... Holy Land and My Uncle Ben!\n",
            "\"Get \"imogen\",\"j\" . \"JANU\n"
          ]
        }
      ],
      "source": [
        "generate(model, max_length=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3jsOZ43Lx6V7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1979b8-1e5f-435c-a211-e03f43cad9d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Where is Springfiled? What about a Rainier?\n",
            "                                               NaN\n",
            "                                      \n",
            "> Where is Springfiled? Should I wait for the next one?\n",
            "Oh that's the hot dog truck for you, Springf...\n",
            "                                              Yes!\n",
            "                       \n",
            "> Where is Springfiled? Should I lay down?\n",
            "                                         Yes, sir.\n",
            "All right, Mr. Kid! I was gonna lay down, but one of my t...\n",
            "                       \n",
            "> Where is Springfiled? How do I get it to Flanders?\n",
            "                                 A plan! A plan!\n",
            "                                             \n",
            "> Where is Springfiled? Where is it?\n",
            "                                                 NaN\n",
            "Marge, you're the first F.B.I. employee to leave in dec...\n",
            "Marge, you're the one who should have told me, bu...\n",
            "Why,\n"
          ]
        }
      ],
      "source": [
        "generate(model, max_length=100, prompts=\"Where is Springfiled?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lUBosKaOycG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465d4b91-d949-4a0d-9e25-4b28ce5ff226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu3VtEmsjKNd",
        "outputId": "7ff3c7f8-0413-4d8e-a6b9-f34b94e3b12a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log  sample_data  simpsons_script_lines.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzs8hrI9qWNd",
        "outputId": "67f16e45-527a-48f1-ee48-97db3449bd4d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log.txt       model_010.pt  model_020.pt  model_030.pt\tmodel_040.pt  model_049.pt\n",
            "model_005.pt  model_015.pt  model_025.pt  model_035.pt\tmodel_045.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(log_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zfoo9CMkjOln",
        "outputId": "84407478-331f-4419-d648-f41bbd2be15d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a94d9ad8-b273-40eb-956a-2f746aa6f533\", \"log.txt\", 12999)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('log/model_040.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UCjaW2QB-hlA",
        "outputId": "2a81c4d6-a183-48c8-d76f-0fd3b92de6b5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0db41b3-7c25-4fb0-95c3-72b3579eed11\", \"model_040.pt\", 497815930)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = GPT(GPTConfig(vocab_size=50257))\n",
        "trained_weights = torch.load(\"log/model_015.pt\")\n",
        "trained_model.load_state_dict({k.strip(\"_orig_mod.\"): v for k, v in trained_weights['model'].items()})\n",
        "trained_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbCQptQ5-mUO",
        "outputId": "2a0ad0d8-8475-473f-985a-3831a97c55a8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): CausalSelfAttention(\n",
              "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): GELU(approximate='tanh')\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT2_model = GPT.from_pretrained('gpt2')\n",
        "GPT2_model.eval()\n",
        "GPT2_model.to(device)"
      ],
      "metadata": {
        "id": "_76gt5Svt66b",
        "outputId": "dfe842c6-2aa5-4b63-d79e-9561b7dab2cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights from pretrained gpt: gpt2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): CausalSelfAttention(\n",
              "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): GELU(approximate='tanh')\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.to(device)"
      ],
      "metadata": {
        "id": "xJq3yEedsU5n",
        "outputId": "f6acf260-4702-407c-8589-a18b4f70844c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): CausalSelfAttention(\n",
              "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): GELU(approximate='tanh')\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = \"Hey, this is Homer Simpson,\"\n",
        "generate(trained_model, num_return_sequences=3, max_length=90, prompts=prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfmdqT7vJ5qw",
        "outputId": "f14957fa-00c5-452f-c85c-dbbe91448812"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Hey, this is Homer Simpson, the guy who gave us the money. Okay, this is him telling us that he made a big mistake by buying this movie.\n",
            "Yes, that's what I thought.\n",
            "What would you do with this baby?\n",
            "Well, this is my house.\n",
            "But I'm not leaving. You'll have to live with me.\n",
            "Marge, I can't take this.\n",
            "So long, sweetie\n",
            "> Hey, this is Homer Simpson, and they're telling us to stop buying his stuff that would be better if you'd bought mine!\n",
            "Well, if you'd like to live like this, then you'll have to pay thirty dollars a year to get rid of my stuff. Then we'll take it out for the babies!\n",
            "You're welcome, you big-ass nerds!\n",
            "What? You came for me? Is that so?\n",
            "\n",
            "> Hey, this is Homer Simpson, and he hasn't gone away. You know his name is Barney Simpson.\n",
            "So, I'm gonna go get my buddy.\n",
            "Well, I'll make you one, but you're gonna say something horrible.\n",
            "Boy, how 'bout that bar-house party you did with your girlfriend?\n",
            "Hey, look at the way they made out.\n",
            "Bart! You could kill me!\n",
            "What\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = \"Hey, Homer, where is Springfiled?\"\n",
        "generate(trained_model, num_return_sequences=2, max_length=90, prompts=prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHds15kzLB1D",
        "outputId": "c01342c3-16c1-4d88-a11b-86f1531df00c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Hey, Homer, where is Springfiled?\n",
            "Oh, I can't help it. Maybe if I'd put some kind of...\n",
            "You mean my car?\n",
            "Oh, I always wanted to be a car guy. Maybe there's a guy who'd like to go all in on the car business.\n",
            "Oh, I just can't. We're too close to the Atlantic Ocean.\n",
            "nan\n",
            "Nope.\n",
            "nan\n",
            "F\n",
            "> Hey, Homer, where is Springfiled?\n",
            "Springfiled.\n",
            "Well, I'll probably use the old trick I learned at school to tell you somethin'.\n",
            "Hey! We got stuck in this mud hole with our hands caked in mud!\n",
            "Hey, what happened to \"Eureka?\"\n",
            "Oh yeah, it's just a fancy name like Springfield.\n",
            "Well what can I do for you guys, Marge?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = \"Hey, this is Homer Simpson,\"\n",
        "generate(GPT2_model, num_return_sequences=2, max_length=80, prompts=prompts)"
      ],
      "metadata": {
        "id": "jRQRwFzFuCvQ",
        "outputId": "48d76705-0461-4e08-ed1e-fd842dd62c7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Hey, this is Homer Simpson, and I want to talk about my work (so much) that a certain part of you gets confused and then you go through the motions of watching it with everyone else. But it's something that really happens to him, and it all goes back to the beginning of his life.\n",
            "\n",
            "How much does he share that with you?\n",
            "\n",
            "It's always the\n",
            "> Hey, this is Homer Simpson, one of the most important characters ever filmed. And they'll talk about where you are and why.\n",
            "\n",
            "\n",
            "Yes, I am going to show you right now the big picture. We're done with the season 7 premiere, and the big announcement this year is that we're gonna have us on the air to bring you one last episode of season six on Thursday,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zt8t6o5hsPjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42be0c5842bd4e3492fc17d7ba98a4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cee0a55f5817436b8ab8a605ff2d09bf",
              "IPY_MODEL_cb47deb852874e768090f0c8fd20dadf",
              "IPY_MODEL_86855a8aaa9a441e84ec5a145e97cb2f"
            ],
            "layout": "IPY_MODEL_6cc63dc3608149dcb61162ac87ce7e9a"
          }
        },
        "cee0a55f5817436b8ab8a605ff2d09bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac01b5330164ba9bc9b82ce2fec1ff7",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc26c7533114cf08afa39a1b9833e5d",
            "value": "config.json: 100%"
          }
        },
        "cb47deb852874e768090f0c8fd20dadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c5b62a1b7664b48a9d27ce28ef62f2e",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdc9354723824e848d8057fd1883f0b9",
            "value": 665
          }
        },
        "86855a8aaa9a441e84ec5a145e97cb2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ce1f8bf0555432cb663ce8fb00d0650",
            "placeholder": "​",
            "style": "IPY_MODEL_f8c4c61c06da4b089c6b49003dd55704",
            "value": " 665/665 [00:00&lt;00:00, 51.3kB/s]"
          }
        },
        "6cc63dc3608149dcb61162ac87ce7e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac01b5330164ba9bc9b82ce2fec1ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc26c7533114cf08afa39a1b9833e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c5b62a1b7664b48a9d27ce28ef62f2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc9354723824e848d8057fd1883f0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ce1f8bf0555432cb663ce8fb00d0650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c4c61c06da4b089c6b49003dd55704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d71bb56039f041a5a2f1bc1b2cd590ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df4789deede24258847c79f71907b9e8",
              "IPY_MODEL_5e56477ce6ae4d8f834042cc8411e7e3",
              "IPY_MODEL_a1a728b8e4b74ea8865e8c51d98f283d"
            ],
            "layout": "IPY_MODEL_38bf219992464b62a93bedffd55c9f9e"
          }
        },
        "df4789deede24258847c79f71907b9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf025bdcbff9425f8f2b9f8c2040b173",
            "placeholder": "​",
            "style": "IPY_MODEL_a0ccd34d18da4c4dafaca8496f4c4f4d",
            "value": "model.safetensors: 100%"
          }
        },
        "5e56477ce6ae4d8f834042cc8411e7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c4c8f924af48298bc27cbfb0e3ff13",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b1ff5cd4661481cb01873df81001b76",
            "value": 548105171
          }
        },
        "a1a728b8e4b74ea8865e8c51d98f283d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adeecd4fd28748558d3986cffbaea0ca",
            "placeholder": "​",
            "style": "IPY_MODEL_6ceff96e1a5c49c9a7edf882326f0070",
            "value": " 548M/548M [00:02&lt;00:00, 276MB/s]"
          }
        },
        "38bf219992464b62a93bedffd55c9f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf025bdcbff9425f8f2b9f8c2040b173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ccd34d18da4c4dafaca8496f4c4f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64c4c8f924af48298bc27cbfb0e3ff13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1ff5cd4661481cb01873df81001b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adeecd4fd28748558d3986cffbaea0ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ceff96e1a5c49c9a7edf882326f0070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd61d64c5af94fc796f9c918a37b09e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e14ef9f0b55246838523137b9e9a3ddd",
              "IPY_MODEL_6b1e127b1cd84a8eb416e11832372e01",
              "IPY_MODEL_b0a80b7561fb47c19c81f84e2b08e10d"
            ],
            "layout": "IPY_MODEL_18b391beb4b74a04b4c4e2344fb725fa"
          }
        },
        "e14ef9f0b55246838523137b9e9a3ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6dba4722226443e8596ac438a139a77",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd222aed2304c7cbad37fc438e68ef9",
            "value": "generation_config.json: 100%"
          }
        },
        "6b1e127b1cd84a8eb416e11832372e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3ba93be2fc421ca235f0cec80dfc4a",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8cd4f6503324588a61ce5f3ab5f9279",
            "value": 124
          }
        },
        "b0a80b7561fb47c19c81f84e2b08e10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e352456322a40eabbe8331a721007ba",
            "placeholder": "​",
            "style": "IPY_MODEL_e318b24efd584ed5a0282da0bbaedb4f",
            "value": " 124/124 [00:00&lt;00:00, 9.75kB/s]"
          }
        },
        "18b391beb4b74a04b4c4e2344fb725fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6dba4722226443e8596ac438a139a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd222aed2304c7cbad37fc438e68ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc3ba93be2fc421ca235f0cec80dfc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cd4f6503324588a61ce5f3ab5f9279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e352456322a40eabbe8331a721007ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e318b24efd584ed5a0282da0bbaedb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}